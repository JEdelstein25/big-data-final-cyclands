{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# France"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Source of original dataset:** https://www.data.gouv.fr/en/datasets/bases-de-donnees-annuelles-des-accidents-corporels-de-la-circulation-routiere-annees-de-2005-a-2019/\n",
    "\n",
    "**Location of accidents:** Latitude, Longitude\n",
    "\n",
    "**Date of accidents:** Date\n",
    "\n",
    "**Outcome of accidents:** Fatality, Hospitalised Injury, Light Injury, PDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_columns', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import numpy as np\n",
    "from plotly import graph_objects as go\n",
    "import plotly.express as px\n",
    "from itertools import chain\n",
    "import matplotlib.pyplot as plt\n",
    "import pyproj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/france/\"\n",
    "\n",
    "characteristics_files = [\"caracteristiques_2005.csv\",\n",
    "                  \"caracteristiques_2006.csv\",\n",
    "                  \"caracteristiques_2007.csv\",\n",
    "                  \"caracteristiques_2008.csv\",\n",
    "                  \"caracteristiques_2009.csv\",\n",
    "                  \"caracteristiques_2010.csv\",\n",
    "                  \"caracteristiques_2011.csv\",\n",
    "                  \"caracteristiques_2012.csv\",\n",
    "                  \"caracteristiques_2013.csv\",\n",
    "                  \"caracteristiques_2014.csv\",\n",
    "                  \"caracteristiques_2015.csv\",\n",
    "                  \"caracteristiques_2016.csv\",\n",
    "                  \"caracteristiques-2017.csv\",\n",
    "                  \"caracteristiques-2018.csv\"]\n",
    "users_files = [\"usagers_2005.csv\",\n",
    "                  \"usagers_2006.csv\",\n",
    "                  \"usagers_2007.csv\",\n",
    "                  \"usagers_2008.csv\",\n",
    "                  \"usagers_2009.csv\",\n",
    "                  \"usagers_2010.csv\",\n",
    "                  \"usagers_2011.csv\",\n",
    "                  \"usagers_2012.csv\",\n",
    "                  \"usagers_2013.csv\",\n",
    "                  \"usagers_2014.csv\",\n",
    "                  \"usagers_2015.csv\",\n",
    "                  \"usagers_2016.csv\",\n",
    "                  \"usagers-2017.csv\",\n",
    "                  \"usagers-2018.csv\"]\n",
    "vehicles_files = [\"vehicules_2005.csv\",\n",
    "                  \"vehicules_2006.csv\",\n",
    "                  \"vehicules_2007.csv\",\n",
    "                  \"vehicules_2008.csv\",\n",
    "                  \"vehicules_2009.csv\",\n",
    "                  \"vehicules_2010.csv\",\n",
    "                  \"vehicules_2011.csv\",\n",
    "                  \"vehicules_2012.csv\",\n",
    "                  \"vehicules_2013.csv\",\n",
    "                  \"vehicules_2014.csv\",\n",
    "                  \"vehicules_2015.csv\",\n",
    "                  \"vehicules_2016.csv\",\n",
    "                  \"vehicules-2017.csv\",\n",
    "                  \"vehicules-2018.csv\"]\n",
    "\n",
    "characteristics_data_files = [data_dir + s for s in characteristics_files]\n",
    "users_data_files = [data_dir + s for s in users_files]\n",
    "vehicles_data_files = [data_dir + s for s in vehicles_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.io.parsers import ParserError\n",
    "characteristics_aux = []\n",
    "users_aux = []\n",
    "vehicles_aux = []\n",
    "\n",
    "\n",
    "for i, (characteristics_data, users_data, vehicles_data) in enumerate(zip(characteristics_data_files, users_data_files, vehicles_data_files)):\n",
    "    if i+2005 == 2009:\n",
    "        sep = '\\t'\n",
    "    else:\n",
    "        sep = ','\n",
    "    \n",
    "    data_characteristics = pd.read_csv(characteristics_data, encoding = \"ANSI\", sep=sep)\n",
    "    data_users = pd.read_csv(users_data, encoding = \"ANSI\", sep=',')\n",
    "    data_vehicles = pd.read_csv(vehicles_data, encoding = \"ANSI\", sep=',')\n",
    "    \n",
    "    print(2005+i, data_characteristics.shape, data_users.shape, data_vehicles.shape)\n",
    "    characteristics_aux.append(data_characteristics)\n",
    "    users_aux.append(data_users)\n",
    "    vehicles_aux.append(data_vehicles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare outcome data from users files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(users_aux)):\n",
    "    users = users_aux[i]\n",
    "    \n",
    "    users['indemme'] = 0\n",
    "    users['tues'] = 0\n",
    "    users['blesse_hosp'] = 0\n",
    "    users['blesse_leg'] = 0\n",
    "    \n",
    "    users.loc[users.grav == 1,'indemme'] = 1\n",
    "    users.loc[users.grav == 2,'tues'] = 1\n",
    "    users.loc[users.grav == 3,'blesse_hosp'] = 1\n",
    "    users.loc[users.grav == 4,'blesse_leg'] = 1\n",
    "    \n",
    "    users = (users.groupby('Num_Acc')\n",
    "              .agg({'indemme': np.sum,\n",
    "                    'tues': np.sum,\n",
    "                    'blesse_hosp': np.sum,\n",
    "                    'blesse_leg': np.sum,})\n",
    "         )\n",
    "    users_aux[i] = users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare bicycles data from users files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(vehicles_aux)):\n",
    "    vehicles = vehicles_aux[i]\n",
    "    \n",
    "    vehicles['bicycles'] = 0\n",
    "    \n",
    "    vehicles.loc[vehicles.catv == 1,'bicycles'] = 1\n",
    "\n",
    "    vehicles = (vehicles.groupby('Num_Acc')\n",
    "                .agg({'bicycles': np.sum})\n",
    "         )\n",
    "    \n",
    "    vehicles_aux[i] = vehicles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aux = []\n",
    "\n",
    "for i in range(len(characteristics_aux)):\n",
    "    data = pd.merge(characteristics_aux[i], users_aux[i], on=\"Num_Acc\", how=\"left\")\n",
    "    data = pd.merge(data, vehicles_aux[i], on=\"Num_Acc\", how=\"left\")\n",
    "    data_aux.append(data)\n",
    "    \n",
    "list_of_dfs = data_aux\n",
    "list_of_dicts = [cur_df.T.to_dict().values() for cur_df in list_of_dfs]    \n",
    "data = pd.DataFrame(list(chain(*list_of_dicts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove rows with invalid lat/long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lat'] = data['lat'].fillna(0)\n",
    "data['long'] = data['long'].fillna(0)\n",
    "\n",
    "data['lat'] = data['lat'].astype('str')\n",
    "data['long'] = data['long'].astype('str')\n",
    "\n",
    "data.loc[data.lat == '-','lat'] = 0\n",
    "data.loc[data.long == '-','long'] = 0\n",
    "\n",
    "data['lat'] = data['lat'].astype('float')\n",
    "data['long'] = data['long'].astype('float')\n",
    "\n",
    "# Fix lat/long negative sign for french colonies\n",
    "data.loc[data.gps == 'Y','lat'] = data.lat*-1\n",
    "data.loc[data.gps == 'R','lat'] = data.lat*-1\n",
    "data.loc[data.gps == 'G','long'] = data.long*-1\n",
    "data.loc[data.gps == 'A','long'] = data.long*-1\n",
    "\n",
    "data = data[(data.lat != 0.0) & (data.long != 0.0)]\n",
    "\n",
    "data['lat'] = 0.00001 * data['lat'].astype('float')\n",
    "data['long'] = 0.00001 * data['long'].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Datetime column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['an'] = data['an'].astype('int') + 2000\n",
    "data['hrmn'] = data['hrmn'].astype('str').str.zfill(4)\n",
    "\n",
    "data['hour'] = data['hrmn'].str[0:2]\n",
    "data['minute'] = data['hrmn'].str[2:4]\n",
    "\n",
    "data['Date'] = data['an'].astype('str') + '/' + data['mois'].astype('str') + '/' + data['jour'].astype('str') + ' ' + data['hour'].astype('str') + ':' + data['minute'].astype('str')\n",
    "data['Date'] = pd.to_datetime(data['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup latitude & longitude column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Longitude'] = data['long']\n",
    "data['Latitude'] = data['lat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some key statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accidents between '+str(data['Date'].min())+' and '+str(data['Date'].max()))\n",
    "\n",
    "total_accidents = data.shape[0]\n",
    "print(\"There are a total of \"+str(total_accidents)+\" accidents.\")\n",
    "\n",
    "fatalities = data[\"tues\"].sum()\n",
    "print(\"There are a total of \"+str(fatalities)+\" fatalities.\")\n",
    "\n",
    "serious_injuries = data[\"blesse_hosp\"].sum()\n",
    "print(\"There are a total of \"+str(serious_injuries)+\" seriously injured.\")\n",
    "\n",
    "light_injuries = data[\"blesse_leg\"].sum()\n",
    "print(\"There are a total of \"+str(light_injuries)+\" injured.\")\n",
    "\n",
    "bicycles = data[\"bicycles\"].sum()\n",
    "print(\"There are a total of \"+str(bicycles)+\" bicycles involved in all the accidents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slice all bicycle accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bicycles = data[data['bicycles']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bicycles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_bicycles.shape)\n",
    "data_bicycles.to_csv('cycling_safety_france.csv')\n",
    "print('Wrote file to: cycling_safety_france.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
