{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detroit, USA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Source of original dataset:** https://semcog.org/traffic-crash-data\n",
    "\n",
    "**Location of accidents:** Latitude, Longitude\n",
    "\n",
    "**Date of accidents:** Date\n",
    "\n",
    "**Outcome of accidents:** Fatalities, A-level Injury, B-level Injury, C-level Injury, PDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_columns', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import numpy as np\n",
    "from plotly import graph_objects as go\n",
    "import plotly.express as px\n",
    "from itertools import chain\n",
    "import matplotlib.pyplot as plt\n",
    "import pyproj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/detroit/\"\n",
    "accident_files = [\"2009-2012_Crash Search Results.csv\",\n",
    "                  \"2013-2015_Crash Search Results.csv\",\n",
    "                  \"2016-2018_Crash Search Results.csv\"]\n",
    "accidents_data_files = [data_dir + s for s in accident_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aux = []\n",
    "\n",
    "for i, accidents_data in enumerate(accidents_data_files):\n",
    "    data_acc = pd.read_csv(accidents_data, encoding = \"ANSI\")\n",
    "    \n",
    "    data_aux.append(data_acc)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dfs = data_aux\n",
    "list_of_dicts = [cur_df.T.to_dict().values() for cur_df in list_of_dfs]    \n",
    "data = pd.DataFrame(list(chain(*list_of_dicts))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Datetime column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['MONTH']=='Jan', 'MONTH'] = '01'\n",
    "data.loc[data['MONTH']=='Feb', 'MONTH'] = '02'\n",
    "data.loc[data['MONTH']=='Mar', 'MONTH'] = '03'\n",
    "data.loc[data['MONTH']=='Apr', 'MONTH'] = '04'\n",
    "data.loc[data['MONTH']=='May', 'MONTH'] = '05'\n",
    "data.loc[data['MONTH']=='Jun', 'MONTH'] = '06'\n",
    "data.loc[data['MONTH']=='Jul', 'MONTH'] = '07'\n",
    "data.loc[data['MONTH']=='Aug', 'MONTH'] = '08'\n",
    "data.loc[data['MONTH']=='Sep', 'MONTH'] = '09'\n",
    "data.loc[data['MONTH']=='Oct', 'MONTH'] = '10'\n",
    "data.loc[data['MONTH']=='Nov', 'MONTH'] = '11'\n",
    "data.loc[data['MONTH']=='Dec', 'MONTH'] = '12'\n",
    "\n",
    "data.loc[data['TIME']=='1am', 'TIME'] = '01:00'\n",
    "data.loc[data['TIME']=='2am', 'TIME'] = '02:00'\n",
    "data.loc[data['TIME']=='3am', 'TIME'] = '03:00'\n",
    "data.loc[data['TIME']=='4am', 'TIME'] = '04:00'\n",
    "data.loc[data['TIME']=='5am', 'TIME'] = '05:00'\n",
    "data.loc[data['TIME']=='6am', 'TIME'] = '06:00'\n",
    "data.loc[data['TIME']=='7am', 'TIME'] = '07:00'\n",
    "data.loc[data['TIME']=='8am', 'TIME'] = '08:00'\n",
    "data.loc[data['TIME']=='9am', 'TIME'] = '09:00'\n",
    "data.loc[data['TIME']=='10am', 'TIME'] = '10:00'\n",
    "data.loc[data['TIME']=='11am', 'TIME'] = '11:00'\n",
    "data.loc[data['TIME']=='12am', 'TIME'] = '12:00'\n",
    "data.loc[data['TIME']=='1pm', 'TIME'] = '13:00'\n",
    "data.loc[data['TIME']=='2pm', 'TIME'] = '14:00'\n",
    "data.loc[data['TIME']=='3pm', 'TIME'] = '1:00'\n",
    "data.loc[data['TIME']=='4pm', 'TIME'] = '16:00'\n",
    "data.loc[data['TIME']=='5pm', 'TIME'] = '17:00'\n",
    "data.loc[data['TIME']=='6pm', 'TIME'] = '18:00'\n",
    "data.loc[data['TIME']=='7pm', 'TIME'] = '19:00'\n",
    "data.loc[data['TIME']=='8pm', 'TIME'] = '20:00'\n",
    "data.loc[data['TIME']=='9pm', 'TIME'] = '21:00'\n",
    "data.loc[data['TIME']=='10pm', 'TIME'] = '22:00'\n",
    "data.loc[data['TIME']=='11pm', 'TIME'] = '23:00'\n",
    "data.loc[data['TIME']=='12pm', 'TIME'] = '00:00'\n",
    "\n",
    "data.loc[data['TIME']=='Unk', 'TIME'] = '00:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Date'] = data['DATE'].astype('str').str.zfill(2) + '/' + data['MONTH'].astype('str') + '/' + data['YEAR'].astype('str') + ' ' +data['TIME'].astype('str')\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup bicycles column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['FACTOR'] = data['FACTOR'].fillna('0')\n",
    "\n",
    "data['bicycle']= 0\n",
    "\n",
    "data['fatal']= 0\n",
    "data['a_level']= 0\n",
    "data['b_level']= 0\n",
    "data['c_level']= 0\n",
    "data['pdo']= 0\n",
    "\n",
    "data.loc[data['FACTOR'].str.contains('B', na=False), 'bicycle'] = 1\n",
    "\n",
    "data.loc[data['SEVERITY'] == 'Fatal', 'fatal'] = 1\n",
    "data.loc[data['SEVERITY'] == 'A-level', 'a_level'] = 1\n",
    "data.loc[data['SEVERITY'] == 'B-level', 'b_level'] = 1\n",
    "data.loc[data['SEVERITY'] == 'C-level', 'c_level'] = 1\n",
    "data.loc[data['SEVERITY'] == 'PDO', 'pdo'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some key statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accidents between '+str(data['Date'].min())+' and '+str(data['Date'].max()))\n",
    "\n",
    "total_accidents = data.shape[0]\n",
    "print(\"There are a total of \"+str(total_accidents)+\" accidents.\")\n",
    "\n",
    "fatalities = data[\"fatal\"].sum()\n",
    "print(\"There are a total of \"+str(fatalities)+\" fatalities.\")\n",
    "\n",
    "pdo = data[\"pdo\"].sum()\n",
    "print(\"There are a total of \"+str(pdo)+\" property damage only accidents.\")\n",
    "\n",
    "bicycles = data[\"bicycle\"].sum()\n",
    "print(\"There are a total of \"+str(bicycles)+\" bicycles involved in all the accidents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slice all bicycle accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bicycles = data[data['bicycle']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bicycles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bicycles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_bicycles.shape)\n",
    "data_bicycles.to_csv('cycling_safety_detroit.csv')\n",
    "print('Wrote file to: cycling_safety_detroit.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
